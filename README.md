# Anthony TMFAS
Emerging Data Scientist in Lagos | WorldQuant University Cert [link to Credly] | Passionate about ML for finance/e-comm.

## Skills
- Python, scikit-learn, XGBoost
- NLP (BERTopic, VADER)
- Data Viz (Plotly, Matplotlib)
- Web Scraping, SQL/BigQuery

### Featured Projects


## Telco Customer Churn Predictor

This is a full-featured data science project that demonstrates how to build, train, and deploy a machine learning model to predict customer churn (when customers cancel their service). We use a public telecom dataset but frame it as a SaaS tool, where "churn" means subscription cancellations.
This README is your complete guideâ€”from downloading the data to launching a live web dashboard. It's designed for everyone:

# Project Outcomes:

Predicted churn risk (0-100%) based on customer profiles.
Provided retention recommendations (e.g., "Offer a discount").
Achieved 85% AUC-ROC accuracy and 72% recall for churners.

Tech Stack: Python, Pandas, Scikit-learn, XGBoost, Streamlit, Plotly. Total time to build: 2-4 weeks part-time.
Live Demo: https://telco-customer-churn-predictor.streamlit.app/ 
Why Build This Project: Churn costs businesses millionsâ€”retaining customers is 5-7x cheaper than acquiring new ones.

Real Impact: Flags 80% of at-risk users early, potentially saving $50K+ in annual revenue (500 users at $50/month).
Portfolio Power: End-to-end skills (data cleaning â†’ ML â†’ deployment)
Business Tie-In: Adaptable to SaaS (tenure = subscription length, charges = plan price).

Dataset: Kaggle Telco Churn (https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
Project Structure
Telco-Customer-Churn-Predictor/
â”œâ”€â”€ dashboard.py                  # Streamlit web app (main entry)
â”œâ”€â”€ requirements.txt              # Install dependencies
â”œâ”€â”€ .gitignore                   # Ignores temp files (e.g., venv/)
â”œâ”€â”€ README.md                    # This file!
â”œâ”€â”€ eda_and_preprocessing.ipynb  # Notebook 1: Data exploration & cleanup
â”œâ”€â”€ modelling.ipynb              # Notebook 2: Model training & evaluation
â”œâ”€â”€ churn_model.pkl              # Saved XGBoost model
â”œâ”€â”€ scaler.pkl                   # Saved data scaler
â”œâ”€â”€ feature_names.pkl            # Feature column names (for app)
â”œâ”€â”€ X_train_scaled.csv           # Processed training data
â”œâ”€â”€ X_test_scaled.csv            # Processed test data
â”œâ”€â”€ y_train.csv                  # Training labels
â”œâ”€â”€ y_test.csv                   # Test labels
â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv  # Raw dataset

Step-by-Step Build Process
Follow this to recreate the project from scratch. Each step includes code, explanations, and tips.
Step 1: Setup Environment
Create a virtual environment to keep things clean.

Open terminal/Command Prompt in a new folder
Create & activate venv:
textpython -m venv venv
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

Install dependencies:
textpip install streamlit pandas scikit-learn xgboost plotly joblib imbalanced-learn seaborn matplotlib jupyter
pip freeze > requirements.txt



Step 2: Download & Explore Data (30 mins)


Download the dataset: Kaggle Link â†’ Save WA_Fn-UseC_-Telco-Customer-Churn.csv to a /data/ folder


Open Jupyter: jupyter notebook â†’ New â†’ Python3 â†’ Create eda_and_preprocessing.ipynb.


Load & Explore
pythonimport pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')
print(df.shape)  # (7043, 21)
print(df.head())
print(df.info())  # Data types, nulls
print(df.describe(include='all'))  # Stats
Explanation: This shows 7K customers with features like "tenure" (months subscribed), "MonthlyCharges" ($), "Churn" (Yes/No target). ~27% churn rateâ€”imbalanced!


Visualize Patterns:
python# Churn distribution
sns.countplot(data=df, x='Churn')
plt.title('Churn Rate: 27%')
plt.show()

# By contract
sns.countplot(data=df, x='Contract', hue='Churn')
plt.title('Churn by Contract Type')
plt.show()
Insights: Month-to-month = 47% churn (vs. 15% for 2-year)â€”target these!


Clean Data:
python# Fix TotalCharges (object â†’ float, drop nulls)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Encode Yes/No to 1/0
yes_no_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']
for col in yes_no_cols:
    df[col] = (df[col] == 'Yes').astype(int)

# One-hot encode categories
cat_cols = ['gender', 'MultipleLines', 'InternetService', 'OnlineBackup', 'DeviceProtection',
            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']
df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Engineer features (SaaS twist)
df_encoded['AvgMonthlyCharge'] = df_encoded['TotalCharges'] / (df_encoded['tenure'] + 1)
df_encoded['LowTenure'] = (df_encoded['tenure'] < df_encoded['tenure'].median()).astype(int)
df_encoded['HighCharge'] = (df_encoded['MonthlyCharges'] > df_encoded['MonthlyCharges'].quantile(0.75)).astype(int)
df_encoded['Contract_Month-to-month'] = ((df_encoded['Contract_One year'] == 0) & (df_encoded['Contract_Two year'] == 0)).astype(int)
df_encoded['ContractRisk'] = df_encoded['Contract_Month-to-month'] * df_encoded['HighCharge']

# Impute any NaNs
num_cols = df_encoded.select_dtypes(include=[np.number]).columns
df_encoded[num_cols] = df_encoded[num_cols].fillna(df_encoded[num_cols].median())

print("Clean shape:", df_encoded.shape)
df_encoded.to_csv('data/clean_data.csv', index=False)


Step 3: Split & Scale Data
pythonfrom sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = df_encoded.drop('Churn', axis=1)
y = df_encoded['Churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Save for later
pd.DataFrame(X_train_scaled, columns=X.columns).to_csv('data/X_train_scaled.csv', index=False)
pd.DataFrame(X_test_scaled, columns=X.columns).to_csv('data/X_test_scaled.csv', index=False)
pd.DataFrame({'Churn': y_train}).to_csv('data/y_train.csv', index=False)
pd.DataFrame({'Churn': y_test}).to_csv('data/y_test.csv', index=False)

import joblib
joblib.dump(scaler, 'src/scaler.pkl')
joblib.dump(X.columns, 'src/feature_names.pkl')

print("Splits saved!")
Explanation: Divides data (80% train, 20% test). Scales features (makes numbers comparable, e.g., tenure vs. charges).
Step 4: Build & Train Model (30 mins)
Create modelling.ipynb:
python# Load data
X_train_scaled = pd.read_csv('data/X_train_scaled.csv').values
X_test_scaled = pd.read_csv('data/X_test_scaled.csv').values
y_train = pd.read_csv('data/y_train.csv')['Churn'].values
y_test = pd.read_csv('data/y_test.csv')['Churn'].values

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Create modelling.ipynb notebook file for modelling part

# Baseline: Logistic
logreg = LogisticRegression(random_state=42, max_iter=1000)
logreg.fit(X_train_scaled, y_train)
y_pred_log = logreg.predict(X_test_scaled)
print("Logistic AUC:", roc_auc_score(y_test, logreg.predict_proba(X_test_scaled)[:,1]))
print(classification_report(y_test, y_pred_log))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_log)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Logistic Confusion Matrix')
plt.show()

# Advanced: XGBoost
xgb = XGBClassifier(n_estimators=100, max_depth=6, random_state=42, eval_metric='auc')
xgb.fit(X_train_scaled, y_train)
y_pred_xgb = xgb.predict(X_test_scaled)
print("XGBoost AUC:", roc_auc_score(y_test, xgb.predict_proba(X_test_scaled)[:,1]))
print(classification_report(y_test, y_pred_xgb))

# Feature Importance
feat_imp = pd.Series(xgb.feature_importances_, index=pd.read_csv('data/X_train_scaled.csv').columns).sort_values(ascending=False)
feat_imp.head(10).plot(kind='barh')
plt.title('Top Features')
plt.show()

# Save Model
joblib.dump(xgb, 'src/churn_model.pkl')
print("Model saved!")
Explanation: Tests simple (Logistic) vs. advanced (XGBoost) models. XGBoost wins (85% AUC). Plot shows top features (e.g., contract type).
Optional: Balance data with SMOTE for better recall:
pythonfrom imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)
xgb.fit(X_train_smote, y_train_smote)  # Retrain
Step 5: Build Dashboard
Create dashboard.py
Run: streamlit run dashboard.py â†’ Browser opens at localhost:8501.
Explanation: Turns model into interactive app. Input profile â†’ Get prob + tips. Batch tab for CSVs.

Step 6: Deploy & Test
Push to GitHub
Deploy: share.streamlit.io â†’ New app â†’ Repo â†’ Main file dashboard.py â†’ Deploy.
Test: Edge cases (tenure=0), metrics match notebooks.


Usage Examples
Single Prediction: Sidebar: Tenure=1, Charges=100, Month-to-month â†’ 75% risk â†’ "Offer discount."
Batch: Upload test CSV â†’ Avg risk 27%.
Model Performance: 85% AUC, 82% accuracy, 72% churn recall.
Business Value: Reduces false negatives by 25% vs. baseline.


## Live demo: https://telco-customer-churn-predictor.streamlit.app/




## ğŸ“Š Twitter Sentiment Analysis Dashboard

This project is my end-to-end implementation of a Twitter Sentiment Analysis Pipeline + Dashboard.
It combines a Jupyter notebook (for preprocessing, sentiment analysis, and exploration) with a Streamlit app (for interactive visualization and deployment).

Tweets were scraped using Twikit, processed in Python, and classified using the CardiffNLP RoBERTa model.

ğŸš€ Features

Jupyter Notebook (offline analysis)

Clean & preprocess tweets (URLs, mentions, hashtags, emojis, etc.)

Run sentiment analysis using CardiffNLP RoBERTa

Save labeled dataset (tweets_labeled.csv)

Generate exploratory plots and word clouds

Streamlit Dashboard (interactive app)

KPIs: Total tweets, Positive %, Neutral %, Negative %

Sentiment distribution (histogram)

Sentiment trend over time (line chart)

Word clouds per sentiment

Sample tweets viewer

Custom text input with "Predict Sentiment" button for live inference

ğŸ›  Tech Stack

Python

Jupyter Notebook â†’ Preprocessing, exploration, and modeling

Streamlit â†’ Interactive dashboard

Pandas â†’ Data wrangling

Plotly & Matplotlib â†’ Visualizations

WordCloud â†’ Text visualization

Transformers (Hugging Face) â†’ Pretrained RoBERTa sentiment model

Torch â†’ Deep learning backend

## ğŸ“‚ Project Structure

Sentiment analysis and time series trend for X posts.ipynb â†’ Jupyter notebook (data processing + analysis)

tweets_labeled.csv â†’ Example dataset (scraped & labeled tweets)

requirements.txt â†’ Dependencies

scraper.py for scraping tweets

tweets_labeled.csv

## Project Link: https://sentiment-analysis-and-time-series-trend-for-x-posts.streamlit.app/

README.md â†’ Project documentation

âš¡ Quickstart
Option 1: Run Notebook

Open Sentiment analysis and time series trend for X posts.ipynb in Jupyter/Colab

Install required dependencies (see requirements.txt)

Run cells to preprocess tweets, classify sentiment, and generate plots

Option 2: Run Streamlit Dashboard

Clone the repository:
git clone https://github.com/your-username/twitter-sentiment-dashboard.git
cd twitter-sentiment-dashboard

Install dependencies:
pip install -r requirements.txt

## ğŸ“Š Example Outputs

Notebook â†’ Sentiment-labeled dataset, static visualizations (distribution, trends, word clouds)

Streamlit App â†’ Interactive dashboard with KPIs, filters, and live sentiment prediction

## ğŸŒ Deployment

This project can be deployed easily on Streamlit Cloud:

Push the repo to GitHub

Go to share.streamlit.io
 and connect your repo

Add requirements.txt

Deploy ğŸš€

ğŸ”® Future Improvements

Real-time tweet scraping instead of static CSV

Multi-language sentiment support

Topic modeling / keyword clustering

Weighted word clouds (TF-IDF instead of raw counts)

## âœ¨ Why I Built This

I wanted to combine data science exploration (via Jupyter notebook) with an interactive web dashboard (via Streamlit).
This workflow helped me practice:

Data preprocessing & NLP pipelines

Using Hugging Face transformers in real projects

Building dashboards for non-technical users

Turning scraped data into actionable insights

This project is both a portfolio piece and a practical tool for sentiment tracking.



### ğŸ›ï¸ Olist Customer Segmentation Project

This project applies **machine learning** to real e-commerce data from the Brazilian marketplace **Olist** to **segment customers** based on their purchasing behavior. It combines **data science**, **API development**, and **web app deployment** into one smooth pipeline.

---

## ğŸš€ What This Project Does

We segment Olistâ€™s customers using **RFM Analysis** (Recency, Frequency, and Monetary Value) and **K-Means Clustering** to uncover valuable patterns, such as:

- ğŸ§Š Low-value customers  
- ğŸ”¥ High-value customers  
- â³ At-risk or dormant customers  
- ğŸ†• New buyers

Users can input RFM metrics into a **Streamlit app**, which communicates with a **FastAPI backend** that runs the trained model and returns the predicted customer segment.

---

## ğŸ› ï¸ Tools & Technologies

| Tool         | Purpose                                   |
|--------------|--------------------------------------------|
| **Pandas**   | Data cleaning and manipulation             |
| **Matplotlib** | Visualization of customer clusters       |
| **Scikit-learn** | K-Means Clustering & StandardScaler    |
| **FastAPI**  | Lightweight API for model serving          |
| **Streamlit**| Interactive frontend web app               |
| **Render**   | Deploying the FastAPI backend online       |
| **Streamlit Cloud** | Deploying the Streamlit frontend    |
| **Git & GitHub** | Version control and project hosting    |

---

## ğŸ“¦ Folder Structure

```
.
â”œâ”€â”€ main.py                 # FastAPI backend code
â”œâ”€â”€ streamlit_app.py        # Frontend Streamlit app
â”œâ”€â”€ kmeans_model.pkl        # Trained clustering model
â”œâ”€â”€ scaler.pkl              # Scaler used to normalize RFM features
â”œâ”€â”€ clustered_rfm.csv       # CSV with original data and predicted clusters
â”œâ”€â”€ requirements.txt        # Required Python libraries
â”œâ”€â”€ README.md               # This file ğŸ˜Š
â””â”€â”€ olist_data/             # Unzipped Olist datasets
```

---

## ğŸ“Š Step-by-Step Breakdown

### 1. **Data Preparation**

- Unzipped `olist_data.zip`, which contains CSVs like:
  - `olist_orders_dataset.csv`
  - `olist_customers_dataset.csv`
  - `olist_order_items_dataset.csv`

- Loaded datasets using `pandas.read_csv`.

- Merged relevant CSVs using `customer_id` and `order_id`.

---

### 2. **Feature Engineering: RFM Table**

For each unique customer, we calculated:

| Feature   | Meaning                                  |
|-----------|-------------------------------------------|
| Recency   | Days since last purchase                  |
| Frequency | Total number of orders                    |
| Monetary  | Total amount spent (sum of item prices)   |

```python
rfm = full_data.groupby('customer_unique_id').agg({
    'order_purchase_timestamp': lambda x: (today - x.max()).days,
    'order_id': 'nunique',
    'price': 'sum'
}).reset_index()
```

---

### 3. **Data Cleaning**

- Removed canceled orders.
- Handled missing values.
- Rounded monetary values to remove centavos.

---

### 4. **Clustering: K-Means**

- Scaled `recency`, `frequency`, and `monetary` using `StandardScaler`.

- Determined the optimal number of clusters using the **elbow method**.

- Trained a K-Means model:

```python
kmeans = KMeans(n_clusters=4, random_state=42)
rfm['cluster'] = kmeans.fit_predict(rfm_scaled)
```

- Saved the model and scaler:

```python
joblib.dump(kmeans, 'kmeans_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
```

---

### 5. **FastAPI Backend**

- Created an API with FastAPI to accept RFM input and return the predicted segment.

```python
@app.post("/predict")
def predict_segment(customer: Customer):
    ...
```

- Hosted on **Render**

---

### 6. **Streamlit Frontend**

- Built an interactive UI to:
  - Accept RFM input
  - Send it to FastAPI
  - Display the predicted segment
  - Visualize cluster distributions

- Read the FastAPI URL securely using Streamlit secrets:

```python
api_url = st.secrets["API_URL"]
```

- Hosted on **Streamlit Cloud**: [streamlit.io/cloud](https://streamlit.io/cloud)

---

## ğŸ“ˆ Visualizations

- **Bar chart** showing the number of customers per cluster
- Optional: Add pie charts, scatter plots, or line trends using `matplotlib` or `seaborn`

---

## ğŸŒ Deployment Steps

1. **Push code to GitHub**
2. **Deploy FastAPI** on Render using:
   - `main.py`
   - `kmeans_model.pkl` and `scaler.pkl`
3. **Live demo**: https://olist-seg.streamlit.app/
   - Use `streamlit_app.py`
   - Set secret in Settings â†’ Secrets:

     ```toml
     API_URL = "https://your-fastapi-url.onrender.com/predict"
     ```

---

## âœ… To Run Locally

1. **Install requirements**

```bash
pip install -r requirements.txt
```

2. **Run FastAPI**

```bash
uvicorn main:app --reload
```

3. **Run Streamlit**

```bash
streamlit run streamlit_app.py
```

---

## ğŸ§  What You Learn

- How to transform raw e-commerce data into actionable clusters.
- How to build, train, and deploy a K-Means clustering model.
- How to create a real-world ML product using APIs and web UIs.
- How to combine multiple modern tools in a full data-to-deployment workflow.

---


## ğŸŒ Live App

ğŸ‘‰ Click here to try the Streamlit App: https://olist-seg.streamlit.app/


## ğŸ™Œ Credits

- Dataset from [Olist e-commerce public dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)
- Streamlit + FastAPI community docs

## Contact
Email: idowunifise@gmail.com | GitHub: [Tony-TMFAS]

Thanks for visitingâ€”let's chat data wins!
